BIG DATA SPARK

Big data(2015 starts):-->>structured,semi structured,unstructured data
structure/traditional data -any data which is in row column ex-csv,rdbms table,excel data 
analysing structured data-We can analyse structured data in excel or in oracle table format easily
semi structured :ex xml file,json file 
some sort of structured but not fully structured like row column format ex-json has key value format 
unstructured data : do not have any kind of structure example: audio file,video file 

Big data -size of the data is really huge in order of terabyte,petabyte 
not only big it's also complex 
real life example -black box data in flight ,everydata store 10 k our 15k data 
social media data is also big data :like facebook/twitter
Size is not only the factor 

5 PROPERTIES OF BIG DATA 
1.volume : size of dsata 
2.variety: different types of data 
3.velocity: deals the speed o data from which data is coming 
4.Value:
5.veracity:talks about quality of data -->>

What is Hadoop: created in 2006
is a platform storing big data across a spectrun of devices 
helps to store and analyse the big data 
open source 
uses parallel processing to analyse huge amount of data 
it's computational layer-mapreduce
storage : hdfs

hadoop gets installed on group of machines
lets say three machine 
each one has 5 terabyte hard disk
all machine 2 cpu 16gb ram 

when install hadoop in all these three machine 

now hadoop will use total 15 TB storage it's called hadoop cluster 

there is 1000 machine in one cluster in real time 

Hadoop can leverage all the three machine cpu and RAM and process the data 

APache Spark :Distributed processing engine for big data 
spark can be installed on top of hadoop 

hadooop will store all the data and spark will process the data 

Runs 100 times faster than hadoop map reduce 
Map reduce is very old big data processing engine 
if we install hadoop by default we will get map reduce engine 

Ease of use 
language 
java scala R python sql 
Java is prefered when 
Spark is written in scala 
so source code is written in scala 
What about python :
Using spark u can do ML on big data 
R is for those people who are coming from data science 
Spark sql is most used in industries

Generality 
Combine sql analytics and streaming 
lets take example of e commerce company 
want to use ml to recommend new products to users 
2nd think 
if they want to analyse the test is called NLP 
thwy would like to analyse chat windows means want to analyse the mood of customers 

ALso they want to 
they like to real time analysis of user data 
by looking at what users are searching on website,they can offer real time deal 

Now s[park can do all above mentioned analyti=cs 

RUns everywhere 
Spark is platform independent 
u can install anywhere 


RDBMS very costly 
u can process 100 terabyte data on oracle but cost of license is very high 

Used cases o Apache Spark AMazon ALibaba,baidue,databricks,ebay,hexabnib,IBM,hitachi,NASA,yahoo,TripAdviser

Spark created in 2009 
university in barkleys 
these people ctreated databricks 
Databricks provides community addition to create our own cluster of 15 GB here 15 GB will work as RAM and 
also this cluster provides some 10 GB of ROM
Databricks has its own notebook where we can not only analyse the data but visualize the data also
 
 
val df=Spark.read.json to read any json file then create a dataframe from this json file 
no need to define any schema and all 

Databricks




